##
# main.fd
# created by Fionn Langhans <fionn.langhans@gmail.com>
#
# This file is part of the Feder compiler. It is the main
# file of the compiler and should be compiled as the main
# file.
##

include "stdio.fd"
include "lexer.fd"
include "help.fd"

if args.length() != 2
    compiler.help.general()
    return false
;

global VERSION = "1.0"

f = File
if !f.open(String from args.at(1), "r")
    io.err.println("Can't open given file")
    return false
;

helper = compiler.lexer.LexerHelper
helper.fn_buffer_readbyte = compiler.lexer.readbyteFile
helper.fn_buffer_close = compiler.lexer.closeFile
helper.buffer = object from f

tokenKeys = int32[0]
tokenValues = String[0]
tokenPositions = int32[0]

if !compiler.lexer.lex(helper, tokenKeys, tokenValues, tokenPositions) || len(tokenKeys) != len(tokenValues)
    io.err.println("- Lexical analysis failed")
    return false
;

String func toAcceptableString(int32 i)
    result = i.toString()
    while result.length() < 4
        result.addto(" ")
    ;

    return result
;

int32 line = 1
io.print(toAcceptableString(line++))

ilast = 0
for i = 0, i < len(tokenKeys), i++
    tokenKey = tokenKeys[i]
    if tokenKey == compiler.LEX_LINE
        if ilast != i
            io.println()
            io.print("    ")
        ;

        for ii = ilast, ii < i, ii++
            if !isEqual(tokenValues[ii], "\n")
                io.print(tokenValues[ii])
            ;

            io.print(" ")
        ;

        ilast = i + 1

        io.println()

        if ilast == len(tokenKeys)
            break
        ;

        io.print(toAcceptableString(line++))
    else
        io.print(compiler.ARRAY_LEX_NAMES[tokenKey])
        io.print (" ")
    ;
;
