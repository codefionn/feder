##
# @file This file offers an lexer, which
# analysis a file with a given buffer. A tokenizer.
##

include "stdio.fd"

namespace compiler
    # Tokens (Keys)

    # Symbols could be the name of a function, variable
    # class, interface, namespace, ...
    global LEX_SYMBOL = 0
    global LEX_KEYWORD = 1
    global LEX_OPERATOR = 2
    global LEX_STRING = 3
    global LEX_CHAR = 4
    global LEX_INTEGER = 5
    global LEX_DOUBLE = 6
    # New line
    global LEX_LINE = 7
    global LEX_COMMAND = 8
    global LEX_BUILDIN = 9
    global LEX_COMMENT = 10
    global LEX_COMMENT_MULTI = 11
    global LEX_COMMENT_MULTI_START = 12
    global LEX_COMMENT_MULTI_END= 13

    ##
    # Contains strings, which should be used, if you want a token (those
    # variables starting with 'LEX_' in the namespace 'compiler') as a string
    ##
    global ARRAY_LEX_NAMES = append(String[0], "symbol", "keyword",
        "operator", "string", "char", "integer", "double", "line",
        "command", "buildin", "comment", "comment-multi",
        "comment-multi-start", "comment-multi-end")

    String func _constructLine_detect(int32 tokenKey)
        if tokenKey == LEX_STRING
            return "\""
        else if tokenKey == LEX_CHAR
            return "\'"
        ;

        return ""
    ;

    ##
    # @param index
    # @param tokenKeys
    # @param tokenValues
    # @param tokenPositions
    # @return Returns an empty string if an error occured or the line
    # is simply empty. Returns a whole line (which like in the original
    # source code) which can be found with index in tokenKeys (searches
    # a new line 'LEX_LINE' which is in front of 'index'. The reconstructs
    # the line from the found index to the next line or the end of tokenValues.
    ##
    String func constructLine(int32 index,
                         int32[] tokenKeys,
                         String[] tokenValues,
                         int32[] tokenPositions)

        if index < 0
            # Correct
            index = 0
        ;

        if index >= len(tokenKeys) || index < 0
            # Exception
            return ""
        ;
        
        if tokenKeys[index] == LEX_LINE
            # Exception
            return ""
        ;
        
        for index > 0 && tokenKeys[index] != LEX_LINE
            index--
        ;

        if tokenKeys[index] == LEX_LINE
            index++
        ;

        String result = String

        for index < len(tokenKeys) && tokenKeys[index] != LEX_LINE, index++
            String s = _constructLine_detect(tokenKeys[index])
            for result.length() + s.length() < tokenPositions[index]
                result += " "
            ;

            result += s
            result += tokenValues[index]
            result += s
        ;

        return result
    ;

    namespace lexer
        ##
        # This interface should provide a function, which reads through
        # a whole buffer (e.g.: A file or string). When the buffer reaches
        # its end, eof ('\0') should be returned.
        # @param The reader (could be file ...)
        # @return Returns a byte in the next buffer position
        ##
        byte interface int_readbyte (object reader)

        ##
        # This interface should provide a function, which closes a give
        # buffer
        # @param reader The buffer, which should be closed
        ##
        interface int_close (object reader)

        ##
        # A function, which can be used by the interface 'int_readByte'.
        # This function reads through a file (that is the buffer).
        ##
        byte func readbyteFile (object reader)
            File file = File from reader
            return file.readByte ()
        ;

        ##
        # A function, which can be used by the interface 'int_close'
        # This function closes a file (that is the buffer).
        ##
        func closeFile (object reader)
            File file = File from reader
            file.close ()
        ;

        byte func readbyteString (object reader0)
            StringReader reader = StringReader from reader0
            return reader.readNext()
        ;

        global String[] operators = append (String[0],
                                    "(", ")", ",", ".", ";",
                                    "[]", "[", "]",
                                    "&&", "||",
                                    "==", "!=", "<=", ">=",
                                    "+=", "-=", "*=", "/=",
                                    "%=", "&=", "|=",
                                    "++", "--",
                                    "=",
                                    "<", ">",
                                    "!", "+", "-", "*", "/",
                                    "&", "|", "^")

        global String[] keywords = append (String[0],
                                   "class", "type", "func", "interface",
                                   "while", "for", "if", "else",
                                   "break", "continue", "return",
                                   "len", "append",
                                   "from",
                                   "true", "false", "null",
                                   "include", "import",
                                   "global", "namespace")
        global KEYWORD_CLASS = 0
        global KEYWORD_TYPE = 1
        global KEYWORD_FUNC = 2
        global KEYWORD_INTERFACE = 3
        global KEYWORD_WHILE = 4
        global KEYWORD_FOR = 5
        global KEYWORD_IF = 6
        global KEYWORD_ELSE = 7
        global KEYWORD_BREAK = 8
        global KEYWORD_CONTINUE = 9
        global KEYWORD_RETURN = 10
        global KEYWORD_LEN = 11
        global KEYWORD_APPEND = 12
        global KEYWORD_FROM = 13
        global KEYWORD_TRUE = 14
        global KEYWORD_FALSE = 15
        global KEYWORD_NULL = 16
        global KEYWORD_INCLUDE = 17
        global KEYWORD_IMPORT = 18
        global KEYWORD_GLOBAL = 19
        global KEYWORD_NAMESPACE = 20

        class LexerHelper
            String name
            String error
            int32 error_count

            String sLine
            int32 iLine
            int32 column

            int32 linesInUnit
            int32 currentScope

            object buffer
            int_readbyte fn_buffer_readbyte
            int_close fn_buffer_close

            byte c

            int32 scopeCurly
            int32 scopeSquare

            bool addComment

            bool addline_direct

            func init
                name = ""
                error = String
                error_count = 0

                sLine = String
                iLine = 0
                column = 0

                linesInUnit = 0
                currentScope = 0

                scopeCurly = 0
                scopeSquare = 0

                addline_direct = false
                addComment = false
            ;

            bool func isKeyword(String s)
                for i = 0, i < len(keywords), i++
                    if isEqual(keywords[i], s)
                        return true
                    ;
                ;

                return false
            ;

            bool func isOperator(String s)
                for i = 0, i < len(operators), i++
                    if isEqual(operators[i], s)
                        return true
                    ;
                ;

                return false
            ;

            byte func readNextChar
                c = fn_buffer_readbyte(buffer)
                column++
                if c != '\n' && c != '\r' && c != '\0' && c != '\t'
                    sLine.addto(Byte.set(c))
                else if c == '\t'
                    column += 3
                    sLine.addto("    ")
                ;

                #io.print(c)

                return c
            ;

            func newLine (int32[] tokenKeys,
                          String[] tokenValues,
                          int32[] tokenPositions)

                for linesInUnit > (-1)
                    linesInUnit--
                    append(tokenKeys, LEX_LINE)
                    append(tokenValues, "\n")
                    append(tokenPositions, 0)
                ;

                linesInUnit = 0

                iLine++
                column = 0
            ;

            func addUnitLine(int32[] tokenKeys,
                             String[] tokenValues,
                             int32[] tokenPositions)
                if addline_direct
                    newLine(tokenKeys, tokenValues, tokenPositions)
                else
                    linesInUnit++
                ;
            ;

            ##
            # Prints an error to the console (msg)
            # but print the line number above and the current text position
            # (with the actual used text)
            # @param tokenKeys
            # @param tokenValues
            # @param msg
            ##
            func newError (int32[] tokenKeys, String[] tokenValues,
                           int32[] tokenPositions,
                           String msg)

                error_count++
                oldColumn = column

                # Read whole line
                readNextChar()
                for c != '\n' && c != '\r' && c != '\0'
                    readNextChar()
                ;

                lastc = c
                readNextChar()
                if (c == '\n' || c == '\r') && c != lastc
                    readNextChar()
                ;


                error += "File=" + name + ", "
                error += "Line=" + iLine + "\n"
                error += sLine
                error += "\n"
                oldColumn--
                for (oldColumn--) > 0
                    error += " "
                ;

                error += "^\n"
                error += "Description="
                error += msg
                error += "\n"

                newLine(tokenKeys, tokenValues, tokenPositions)
                io.err.println(error)
            ;
        ;

        ##
        # Should work on a string or character. The current character
        # (helper.c) should be '"' or '\'' (Not the next character).
        # @param helper
        # @param tokenKeys
        # @param tokenValues
        ##
        func _workOnString(LexerHelper helper,
                           int32[] tokenKeys,
                           String[] tokenValues,
                           int32[] tokenPositions)

            String buffer_tokenValue = String

            cbegin = helper.c
            helper.readNextChar()
            ignore = false

            beginColumn = helper.column

            while (ignore || helper.c != cbegin) && helper.c != '\0'
                if helper.c == '\n' || helper.c == '\r'
                    begin_line = helper.c
                    helper.readNextChar()
                    if (helper.c == '\n' || helper.c == '\r') && helper.c != begin_line
                        helper.readNextChar()
                    ;
                            
                    helper.addUnitLine(tokenKeys, tokenValues, tokenPositions)
                    continue
                ;
                        
                buffer_tokenValue.addto(Byte.set(helper.c))

                if !ignore && helper.c == '\\'
                    ignore = true
                else if ignore
                    # TODO: Check if character is really an escape-able character
                    ignore = false
                ;
                
                # Read in next character
                helper.readNextChar()
            ;

            if helper.c == '\0'
                helper.newError(tokenKeys, tokenValues,
                    tokenPositions,
                    "String not closed")
                return
            ;

            if cbegin == '\''
                append(tokenKeys, LEX_CHAR)
            else if cbegin == '\"'
                append(tokenKeys, LEX_STRING)
            else
                helper.newError(tokenKeys, tokenValues,
                    tokenPositions,
                    "Internal error")
                return
            ;

            append(tokenValues, buffer_tokenValue)
            append(tokenPositions, beginColumn)
            helper.readNextChar()
        ;

        ##
        # Should work on a comment. The current character (helper.c)
        # should be '# (Not the next character)'
        # @param helper
        # @param tokenKeys
        # @param tokenValues
        ##
        bool func _workOnComment(LexerHelper helper,
                            int32[] tokenKeys,
                            String[] tokenValues,
                            int32[] tokenPositions)

            String buffer_tokenValue = String
            oldColumn = helper.column
            oldLine = helper.iLine
            
            helper.readNextChar()
            bool isFirst = true
            if helper.c == '#'
                # It's a (possible) multi line comment
                helper.readNextChar()
                while helper.c != '\0'
                    if helper.c == '#'
                        helper.readNextChar()
                        if helper.c == '#'
                            break
                        ;

                        if helper.addComment
                            buffer_tokenValue.addto(Byte.set('#'))
                        ;

                        continue
                    ;

                    if helper.c == '\n' || helper.c == '\r'
                        # A new line has been started
                        cbegin = helper.c
                        helper.readNextChar()
                        if (helper.c == '\n' || helper.c == '\r') && helper.c != cbegin
                            helper.readNextChar()
                        ;

                        if helper.addComment
                            if isFirst
                                append(tokenKeys, LEX_COMMENT_MULTI_START)
                                isFirst = false
                            else
                                append(tokenKeys, LEX_COMMENT)
                            ;

                            append(tokenValues, buffer_tokenValue)
                            append(tokenPositions, oldColumn)
                            buffer_tokenValue = String
                        ;

                        # No lines must be added,
                        # because the source code unit could continue
                        # following the end of this comment
                        helper.addUnitLine(tokenKeys, tokenValues, tokenPositions)
                        continue
                    ;
                    
                    if helper.addComment
                        buffer_tokenValue.addto(Byte.set(helper.c))
                    ;

                    helper.readNextChar()
                ;

                if helper.c == '\0'
                    # Comment ended, but not with ##
                    io.err.println("Comment didn't end")
                    helper.error_count++
                    return false
                ;

                if helper.c != '\0'
                    helper.readNextChar()
                ;

                if helper.addComment
                    if isFirst
                        append(tokenKeys, LEX_COMMENT_MULTI)
                    else
                        append(tokenKeys, LEX_COMMENT_MULTI_END)
                    ;

                    append(tokenValues, buffer_tokenValue)
                    append(tokenPositions, oldColumn)
                ;
            
                # End multi line comment
                return true
            ;

            # It's a single line comment
            while helper.c != '\0' && helper.c != '\n' && helper.c != '\r'
                if helper.addComment
                    buffer_tokenValue.addto(Byte.set(helper.c))
                ;
                helper.readNextChar()
            ;

            if helper.addComment
                append(tokenKeys, LEX_COMMENT)
                append(tokenValues, buffer_tokenValue)
                append(tokenPositions, oldColumn)
            ;

            return true
        ;

        ##
        # Should work on commands and buildins. The current character should
        # be ':' (Not the next character).
        # @param helper
        # @param tokenKeys
        # @param tokenValues
        ##
        func _workOnCommand(LexerHelper helper,
                            int32[] tokenKeys,
                            String[] tokenValues,
                            int32[] tokenPositions)

            # Current character is ':', so read new one
            helper.readNextChar()
            String buffer_tokenValue = String

            iscommand = false
            if helper.c == ':'
                # Started with '::' => Command
                iscommand = true
                # Current char ':' (used in last comparison,
                # we need a new one) => read new one
                helper.readNextChar()
            ;

            # Read till the end of the line
            for helper.c != '\r' && helper.c != '\n' && helper.c != '\0'
                buffer_tokenValue.addto(Byte.set(helper.c))
                helper.readNextChar()
            ;

            # Command '::', Build-in ':'
            if iscommand
                append(tokenKeys, LEX_COMMAND)
            else
                append(tokenKeys, LEX_BUILDIN)
            ;

            append(tokenValues, buffer_tokenValue)
            append(tokenPositions, helper.column - buffer_tokenValue.length())
        ;

        ##
        # This function reads through the given 'buffer' (in 'helper') with the
        # interface fn_buffer_readbyte (in 'helper'). If the buffer's end has
        # been reached, the buffer will be closed by 'fn_buffer_close' (in
        # 'helper').
        # 
        # @param tokenKeys The result of lexer (tokenizer), These are tokens,
        # which described the elements in 'tokenValues' (The elements of this
        # array can have the values from 'compiler.LEX_*' (wildcard)
        # @param tokenValues The result of the lexer (tokennizer). The elements
        # of this list are the real values, described by 'tokenKeys'.
        # 
        # @return Returns true, if the Lexer processed the buffer successfully.
        # If an error occures, while processing the buffer, the error
        # description is added to 'error'.
        ##
        bool func lex (LexerHelper helper,
                       int32[] tokenKeys,
                       String[] tokenValues,
                       int32[] tokenPositions)
            
            String buffer_tokenValue = String

            # Read first character
            helper.readNextChar()
            for helper.c != '\0'
                if helper.c == '\n' || helper.c == '\r'
                    # Detected a new line
                    lastc = helper.c
                    helper.readNextChar()
                    if (helper.c == '\n' || helper.c == '\r')  && helper.c != lastc
                        # The detected line is a CRLF or LFCR
                        helper.readNextChar()
                    ;

                    if helper.scopeCurly == 0 && helper.scopeSquare == 0
                        helper.newLine(tokenKeys, tokenValues, tokenPositions)
                    else
                        helper.addUnitLine(tokenKeys, tokenValues, tokenPositions)
                    ;

                    continue
                ;

                # Ignore 'spaces'
                if helper.c == '\t' || helper.c == ' '
                    helper.readNextChar()
                    continue
                ;

                # Start of a single line or multi line comment
                if helper.c == '#'
                    _workOnComment(helper, tokenKeys, tokenValues, tokenPositions)
                    continue
                ;

                # Start of commands or build-ins (both starting with ':')
                if (len(tokenKeys) == 0
                    || tokenKeys[len(tokenKeys) - 1] == LEX_LINE) && helper.c == ':'
                    
                    _workOnCommand(helper, tokenKeys, tokenValues, tokenPositions)
                    continue
                ;

                # Check if character or string (character which starts
                # those are '\'' or '"'
                if helper.c == '\"' || helper.c == '\''
                    _workOnString(helper, tokenKeys, tokenValues, tokenPositions)
                    continue
                ;

                buffer_tokenValue.addto(Byte.set(helper.c))
                bool isBufferOperator = false
                for (helper.c != '\t' && helper.c != ' '
                    && helper.c != '\n' && helper.c != '\r'
                    && helper.c != '\0'
                    && helper.isOperator(buffer_tokenValue))

                    if !isBufferOperator
                        isBufferOperator = true
                    ;

                    # Still an operator
                    buffer_tokenValue.addto(Byte.set(helper.readNextChar()))
                ;

                if isBufferOperator
                    if !helper.isOperator(buffer_tokenValue)
                        buffer_tokenValue.removeAt(buffer_tokenValue.length()-1)
                    ;

                    append(tokenKeys, LEX_OPERATOR)
                    append(tokenValues, buffer_tokenValue)
                    append(tokenPositions, helper.column - buffer_tokenValue.length())

                    # scopes (brackets)
                    if isEqual(buffer_tokenValue, "(")
                        helper.scopeCurly++
                    else if isEqual(buffer_tokenValue, "[")
                        helper.scopeSquare++
                    else if isEqual(buffer_tokenValue, ")")
                        helper.scopeCurly--
                        if helper.scopeCurly < 0
                            helper.newError(tokenKeys,
                                            tokenValues,
                                            tokenPositions,
                                            "One or more '(' are missing or this sign is too much!")
                            helper.scopeCurly = 0
                        ;
                    else if isEqual(buffer_tokenValue, "]")
                        helper.scopeSquare--
                        if helper.scopeSquare < 0
                            helper.newError(tokenKeys,
                                            tokenValues,
                                            tokenPositions,
                                            "One or more '[' are missing or this sign is too much!")
                            helper.scopeSquare = 0
                        ;
                    ;

                    buffer_tokenValue = String
                    continue
                ;

                # Unknown ?
                if !helper.c.isDigit() && !helper.c.isAlpha() && helper.c != '_'

                    # Well, buffer_tokenValue contains something that is not
                    # an operator, but is also not applyable as a symbol
                    helper.newError(tokenKeys,
                                    tokenValues,
                                    tokenPositions, "Unknown operator")
                    continue
                ;

                # Read the next character, last one was already added to
                # buffer_tokenValue
                helper.readNextChar()

                # Read the symbol (only digits, alphabetic characters and '_'
                # are allowed)
                for helper.c.isDigit() || helper.c.isAlpha() || helper.c == '_'
                    buffer_tokenValue.addto(Byte.set(helper.c))
                    helper.readNextChar()
                ;

                if (buffer_tokenValue.isNumber(false)
                    || buffer_tokenValue.isHexadecimal())

                    # buffer_tokenValue is an integer
                    append(tokenKeys, LEX_INTEGER)
                    append(tokenValues, buffer_tokenValue)
                    append(tokenPositions, helper.column - buffer_tokenValue.length())
                    buffer_tokenValue = String
                    continue
                else if buffer_tokenValue.isNumber(true)
                    # buffer_tokenValue is a floating point number
                    append(tokenKeys, LEX_DOUBLE)
                    append(tokenValues, buffer_tokenValue)
                    append(tokenPositions, helper.column - buffer_tokenValue.length())
                    buffer_tokenValue = String
                    continue
                else if buffer_tokenValue.at(0).val.isDigit()
                    helper.newError(tokenKeys, tokenValues, tokenPositions,
                        "Invalid Symbol, because a symbol can't start with a digit!")
                    buffer_tokenValue = String
                    continue
                else
                    # Could still be a keyword
                    if helper.isKeyword(buffer_tokenValue)
                        append(tokenKeys, LEX_KEYWORD)
                    else
                        # Not a keyword, an ordinary symbol
                        append(tokenKeys, LEX_SYMBOL)
                    ;

                    # The value is the same, regardless of the the
                    # values token type
                    append(tokenValues, buffer_tokenValue)

                    append(tokenPositions, helper.column - buffer_tokenValue.length())

                    # Reset the tokenValue buffer
                    buffer_tokenValue = String
                    continue
                ;

                # Unknown character
                helper.newError(tokenKeys,
                                tokenValues,
                                tokenPositions, "Invalid character")
            ;

            if helper.fn_buffer_close != null
                helper.fn_buffer_close(helper.buffer)
            ;

            # error_count is null => No error occured
            return helper.error_count == 0
        ;
    ;
;
