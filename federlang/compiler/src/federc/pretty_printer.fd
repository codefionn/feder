##
# federc/pretty_printer.fd
# created by Fionn Langhans <fionn.langhans@gmail.com>
#
# This file is a pretty printer for humans
##

include "stdio.fd"
include "federc/help.fd"
include "federc/lexer.fd"

namespace compiler
    namespace pretty
        ##
        # This function was written for the function below:
        # command(args). It reads a files (path given: files[i])
        # and adds the result to TokenKeys, TokenValues, TokenPositions
        ##
        bool func _readFile(String[] files, int32 i,
                            int32[] TokenKeys,
                            String[] TokenValues,
                            int32[] TokenPositions,
                            
                            String suffix)

            File f = File
            if !f.open(files[i], "r")
                io.err.print("Can't read file ")
                io.err.println(files[i])
                return false
            ;

            # Give the user a message
            io.print("Pretty printing file ")
            io.print(files[i])
            if suffix.isEmpty()
                io.println()
            else
                io.print(" to ")
                io.print(files[i])
                io.print(suffix)
                io.println()
            ;

            Lex = compiler.lexer.LexerHelper
            #Lex.addline_direct = true
            Lex.name = files[i]
            Lex.buffer = object from f
            Lex.addComment = true
            Lex.fn_buffer_readbyte = compiler.lexer.readbyteFile
            Lex.fn_buffer_close = compiler.lexer.closeFile


            if !compiler.lexer.lex(Lex,
                    TokenKeys, TokenValues, TokenPositions)
                # No notice for now
                # if you think it is neccessary email me
                return false
            ;

            return true
        ;

        func _writeTo(File file, String s)
            io.print(s)
        ;

        ##
        # This function checks if the newline written by the 
        # programmer should be written to the pretty version
        # or not
        # @param i 0 <= i < len(tokenKeys)
        # @param tokenKeys
        # @param tokenValues never null and len(tokenKeys) == len(tokenValues)
        ##
        bool func _shouldWriteNewLine(int32 i,
                                      int32[] tokenKeys,
                                      String[] tokenValues)
            if i > 1 && tokenKeys[i-1] == LEX_LINE && ((
                isEqual(tokenKeys[i-2], LEX_OPERATOR) &&
                    !isEqual(tokenValues[i-2], ";"))
                || !isEqual(tokenKeys[i-2], LEX_OPERATOR))

                return false
            ;

            return true
        ;

        ##
        # @param lastTokenKey
        # @param lastTokenValue
        # @param currentTokenKey
        # @param currentTokenValue
        # @return Returns true, if a new space character should
        # be written between lastTokenKey and currentTokenKey
        ##
        bool func _shouldWriteSpace(int32 lastTokenKey,
                                    String lastTokenValue,
                                    int32 currentTokenKey,
                                    String currentTokenValue)
            if isEqual(lastTokenKey, LEX_LINE)
                return false
            ;

            if isEqual(lastTokenKey, LEX_KEYWORD) && (
                isEqual(lastTokenValue, lexer.keywords[lexer.KEYWORD_FOR])
                || isEqual(lastTokenValue, lexer.keywords[lexer.KEYWORD_WHILE])
                || isEqual(lastTokenValue, lexer.keywords[lexer.KEYWORD_IF]))

                return true
            ;

            if isEqual(lastTokenKey, LEX_OPERATOR) && (
                isEqual(lastTokenValue, "(")
                || isEqual(lastTokenValue, "[")
                || isEqual(lastTokenValue, "!")
                || isEqual(lastTokenValue, ";")
                || isEqual(lastTokenValue, "."))

                return false
            ;

            if isEqual(currentTokenKey, LEX_OPERATOR) && (
                isEqual(currentTokenValue, ".")
                || isEqual(currentTokenValue, "(")
                || isEqual(currentTokenValue, ")")
                || isEqual(currentTokenValue, "]")
                || isEqual(currentTokenValue, ","))

                return false
            ;

            return true
        ;

        bool interface int_printToBuffer(object buffer, String s)

        # Applyable to int_printToBuffer
        bool func printToFile(object buffer, String s)
            return (File from buffer).write(s)
        ;

        ##
        # @param args object at index 0 should be "style"
        # (the command which invokes this one)
        ##
        bool func command(String[] args)
            if len(args) == 1
                compiler.help.err()
            ;

            String[] files = String[0]
            String suffix = ""
            String tab = "    "
            int32 tab_length = 4

            int32 flag = 0
            FLAG_FILENAME = 0
            FLAG_SUFFIX = 1
            FLAG_TAB = 2

            for i = 1, i < len(args), i++
                if args[i].startsWith("-")
                    if isEqual(args[i], "-suffix")
                        flag = FLAG_SUFFIX
                    else if isEqual(args[i], "-tab")
                        flag = FLAG_TAB
                    else
                        compiler.help.err_unknown_option(args[i])
                        return false
                    ;
                else if flag != FLAG_FILENAME
                    if flag == FLAG_SUFFIX
                        suffix = args[i]
                    else if flag == FLAG_TAB
                        suffix = args[i]
                    ;
                else if args[i].startsWith("\\-")
                    # Ignore first - (would be option)
                    append(files, args[i].subString(2))
                else
                    append(files, args[i])
                ;
            ;

            tokenKeys = int32[0]
            tokenValues = String[0]
            tokenPositions = int32[0]

            for i = 0, i < len(files), i++
                if !_readFile(files, i,
                    tokenKeys, tokenValues, tokenPositions, suffix)

                    # Reset
                    tokenKeys = int32[0]
                    tokenValues = String[0]
                    tokenPositions = int32[0]
                    continue
                ;

                int32 scope = 0
                bool scopeNextAdd = false
                int32 int_scope = 0
                int32 column = 0
                File fileOutput = null
                bool inMultiComment = false
                
                for i = 0, i < len(tokenKeys), i++
                    if (isEqual(tokenKeys[i], LEX_KEYWORD)
                        && (isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_IF])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_ELSE])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_CLASS])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_NAMESPACE])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_FUNC])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_FOR])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_WHILE])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_TYPE])))

                        scopeNextAdd = true
                    ;

                    if (isEqual(tokenKeys[i], LEX_OPERATOR)
                        && (isEqual(tokenValues[i], "(")
                            || isEqual(tokenValues[i], "[")))

                        int_scope++
                    else if (isEqual(tokenKeys[i], LEX_OPERATOR)
                        && (isEqual(tokenValues[i], ")")
                            || isEqual(tokenValues[i], "]")))
                        
                        int_scope--
                    ;

                    if isEqual(tokenKeys[i], LEX_LINE)
                        column = 0
                        if _shouldWriteNewLine(i, tokenKeys, tokenValues)
                            _writeTo(fileOutput, "\n")
                        ;
     
                        if scopeNextAdd
                            scope++
                            scopeNextAdd = false
                        ;                       

                        if ((i + 1) < len(tokenKeys)
                            && ((isEqual(tokenKeys[i + 1], LEX_OPERATOR)
                                && isEqual(tokenValues[i + 1], ";"))
                                    || (isEqual(tokenKeys[i + 1], LEX_KEYWORD)
                                && isEqual(tokenValues[i + 1], "else"))))

                            scope--
                        ;

                        if ((i + 1) < len(tokenKeys)
                            && tokenKeys[i + 1] != LEX_LINE)
                            # We should write a bit space in front of this line
                            # (because it's not an empty one)

                            for ii = 0, ii < scope + int_scope, ii++
                                _writeTo(fileOutput, tab)
                                if isEqual(tab, "\t")
                                    column += tab_length
                                else
                                    column += tab.length()
                                ;
                            ;
                        ;

                        continue
                    ;

                    if !inMultiComment && i > 0 && _shouldWriteSpace(tokenKeys[i-1],
                        tokenValues[i-1],
                        tokenKeys[i], tokenValues[i])
                            
                        _writeTo(fileOutput, " ")
                        column += 1
                    ;

                    String startValue = null
                    String endValue = null
                    if tokenKeys[i] == LEX_STRING
                        startValue = "\""
                        endValue = startValue
                    else if tokenKeys[i] == LEX_CHAR
                        startValue = "\'"
                        endValue = startValue
                    else if tokenKeys[i] == LEX_COMMENT
                        tokenValues[i].trim()
                        if !tokenValues[i].startsWith("#")
                            tokenValues[i].insert("# ", 0)
                        ;

                        if inMultiComment || ((i + 1) < len(tokenKeys)
                                && tokenKeys[i + 1] != LEX_LINE)
                            endValue = "\n"
                        ;
                    else if tokenKeys[i] == LEX_COMMENT_MULTI
                        startValue = "##"
                        endValue = "##"
                    else if tokenKeys[i] == LEX_COMMENT_MULTI_END
                        inMultiComment = false
                        endValue = "##"
                    else if tokenKeys[i] == LEX_COMMENT_MULTI_START
                        inMultiComment = true
                        startValue = "##"
                        endValue = "\n"
                        for ii = 0, ii < scope + int_scope, ii++
                            endValue += tab
                            if isEqual(tab, "\t")
                                column += tab_length
                            else
                                column += tab.length()
                            ;
                        ;
                    ;
                    
                    if int_scope > 0 && column >= 40 && isEqual(tokenKeys[i], LEX_OPERATOR) && (
                        isEqual(tokenValues[i], "||")
                        || isEqual(tokenValues[i], "&&"))
                        
                        column = 0
                        _writeTo(fileOutput, "\n")
                        for ii = 0, ii < scope + int_scope, ii++
                            _writeTo(fileOutput, tab)
                            if isEqual(tab, "\t")
                                column += tab_length
                            else
                                column += tab.length()
                            ;
                        ;
                    ;

                    if int_scope > 0 && (tokenKeys[i] == LEX_SYMBOL
                        || tokenKeys[i] == LEX_STRING
                        || tokenKeys[i] == LEX_CHAR)
                        
                        lenToken = tokenValues[i].length()
                        if (tokenKeys[i] == LEX_STRING
                            || tokenKeys[i] == LEX_CHAR)

                            lenToken += 2
                        ;

                        if column + lenToken >= 80
                            column = 0
                            _writeTo(fileOutput, "\n")
                            for ii = 0, ii < scope + int_scope, ii++
                                _writeTo(fileOutput, tab)
                                if isEqual(tab, "\t")
                                    column += tab_length
                                else
                                    column += tab.length()
                                ;
                            ;
                        ;
                    ;

                    if startValue != null
                        _writeTo(fileOutput, startValue)
                        column += startValue.length()
                    ;
    
                    _writeTo(fileOutput, tokenValues[i])
                    column += tokenValues[i].length()

                    if endValue != null
                        _writeTo(fileOutput, endValue)
                        column += endValue.length()
                    ;

                    if int_scope > 0 && column >= 40 && isEqual(tokenKeys[i], LEX_OPERATOR) && (
                        isEqual(tokenValues[i], ","))
                        
                        column = 0
                        _writeTo(fileOutput, "\n")
                        for ii = 0, ii < scope + int_scope, ii++
                            _writeTo(fileOutput, tab)
                            if isEqual(tab, "\t")
                                column += tab_length
                            else
                                column += tab.length()
                            ;
                        ;
                    ;
                ;
            ;

            return true
        ;
    ;
;
