##
# federc/pretty_printer.fd
# created by Fionn Langhans <fionn.langhans@gmail.com>
#
# This file is a pretty printer for humans
##

include "stdio.fd"
include "federc/help.fd"
include "federc/lexer.fd"

namespace compiler
    namespace pretty
        ##
        # This function was written for the function below:
        # command(args). It reads a files (path given: files[i])
        # and adds the result to TokenKeys, TokenValues, TokenPositions
        ##
        bool func _readFile(String[] files, int32 i,
                            int32[] TokenKeys,
                            String[] TokenValues,
                            int32[] TokenPositions,
                            
                            String suffix)

            Lex = compiler.lexer.LexerHelper
            Lex.name = files[i]

            if isEqual(files[i], "-")
                String buffer = String
                byte c = io.readByte()
                io.println("Reading from stdin")
                while c != '\0'
                    buffer.addto(Byte.set(c))
                    c = io.readByte()
                ;

                Lex.buffer = object from StringReader.new(buffer)
                Lex.fn_buffer_readbyte = compiler.lexer.readbyteString
                Lex.fn_buffer_close = null
            else 
                File f = File
                if !f.open(files[i], "r")
                    io.err.print("Can't read file ")
                    io.err.println(files[i])
                    return false
                ;

                Lex.buffer = object from f
                Lex.fn_buffer_readbyte = compiler.lexer.readbyteFile
                Lex.fn_buffer_close = compiler.lexer.closeFile
            ;

            Lex.addComment = true

            if !compiler.lexer.lex(Lex,
                    TokenKeys, TokenValues, TokenPositions)
                # No notice for now
                # if you think it is neccessary email me
                return false
            ;   

            return true
        ;

        func _writeTo(File file, String s)
            io.print(s)
        ;

        ##
        # This function checks if the newline written by the 
        # programmer should be written to the pretty version
        # or not
        # @param i 0 <= i < len(tokenKeys)
        # @param tokenKeys
        # @param tokenValues never null and len(tokenKeys) == len(tokenValues)
        ##
        bool func _shouldWriteNewLine(int32 i,
                                      int32[] tokenKeys,
                                      String[] tokenValues)
            if i > 1 && tokenKeys[i-1] == LEX_LINE && ((
                isEqual(tokenKeys[i-2], LEX_OPERATOR) &&
                    !isEqual(tokenValues[i-2], ";"))
                || !isEqual(tokenKeys[i-2], LEX_OPERATOR))

                return false
            ;

            return true
        ;

        ##
        # @param lastTokenKey
        # @param lastTokenValue
        # @param currentTokenKey
        # @param currentTokenValue
        # @return Returns true, if a new space character should
        # be written between lastTokenKey and currentTokenKey
        ##
        bool func _shouldWriteSpace(int32 lastTokenKey,
                                    String lastTokenValue,
                                    int32 currentTokenKey,
                                    String currentTokenValue)
            if isEqual(lastTokenKey, LEX_LINE)
                return false
            ;

            if isEqual(lastTokenKey, LEX_KEYWORD) && (
                isEqual(lastTokenValue, lexer.keywords[lexer.KEYWORD_FOR])
                || isEqual(lastTokenValue, lexer.keywords[lexer.KEYWORD_WHILE])
                || isEqual(lastTokenValue, lexer.keywords[lexer.KEYWORD_IF]))

                return true
            ;

            if isEqual(lastTokenKey, LEX_OPERATOR) && (
                isEqual(lastTokenValue, "(")
                || isEqual(lastTokenValue, "[")
                || isEqual(lastTokenValue, "!")
                || isEqual(lastTokenValue, ";")
                || isEqual(lastTokenValue, "."))

                return false
            ;

            if isEqual(currentTokenKey, LEX_OPERATOR) && (
                isEqual(currentTokenValue, ".")
                || isEqual(currentTokenValue, "(")
                || isEqual(currentTokenValue, ")")
                || isEqual(currentTokenValue, "]")
                || isEqual(currentTokenValue, "[")
                || isEqual(currentTokenValue, ",")
                || isEqual(currentTokenValue, "[]"))

                return false
            ;

            return true
        ;

        bool interface int_printToBuffer(object buffer, String s)

        # Applyable to int_printToBuffer
        bool func printToFile(object buffer, String s)
            return (File from buffer).write(s)
        ;

        ##
        # @param args object at index 0 should be "style"
        # (the command which invokes this one)
        ##
        bool func command(String[] args)
            if len(args) == 1
                compiler.help.err(args[0])
                return false
            ;

            String[] files = String[0]
            String suffix = ""
            String tab = "    "
            int32 tab_length = 4

            int32 flag = 0
            FLAG_FILENAME = 0
            FLAG_SUFFIX = 1
            FLAG_TAB = 2

            for i = 1, i < len(args), i++
                if isEqual(flag, FLAG_FILENAME) && args[i].startsWith("-")
                    if isEqual(args[i], "-suffix")
                        flag = FLAG_SUFFIX
                    else if isEqual(args[i], "-tab")
                        flag = FLAG_TAB
                    else
                        compiler.help.err_unknown_option(args[0], args[i])
                        return false
                    ;
                else if flag != FLAG_FILENAME
                    if flag == FLAG_SUFFIX
                        suffix = args[i]
                    else if flag == FLAG_TAB
                        suffix = args[i]
                    ;
                else if args[i].startsWith("\\-")
                    # Ignore first - (would be option)
                    append(files, args[i].cp().removeAt(0))
                else
                    append(files, args[i])
                ;
            ;

            if len(files) == 0
                compiler.help.err(args[0])
                return false
            ;

            tokenKeys = int32[0]
            tokenValues = String[0]
            tokenPositions = int32[0]

            for i = 0, i < len(files), i++
                if !_readFile(files, i,
                    tokenKeys, tokenValues, tokenPositions, suffix)

                    # Reset
                    tokenKeys = int32[0]
                    tokenValues = String[0]
                    tokenPositions = int32[0]
                    continue
                ;

                # 'global' scope started by: class, func, if, else
                # namespace, for, while, type
                int32 scope = 0
                bool scopeNextAdd = false
                # int_scope = internal scope
                int32 int_scope = 0
                # the column counted in the current line
                # important for: Do not use more than 80 characters in a line
                int32 column = 0
                File fileOutput = null
                bool inMultiComment = false

                int32 startSoftCut = 60
                int32 startHardCut = 80
                
                for i = 0, i < len(tokenKeys), i++
                    if (isEqual(tokenKeys[i], LEX_KEYWORD)
                        && (isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_IF])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_ELSE])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_CLASS])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_NAMESPACE])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_FUNC])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_FOR])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_WHILE])
                            || isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_TYPE])))

                        scopeNextAdd = true
                    ;

                    if (isEqual(tokenKeys[i], LEX_OPERATOR)
                        && (isEqual(tokenValues[i], "(")
                            || isEqual(tokenValues[i], "[")))

                        # int_scope = internal scope
                        # someting in () or []
                        int_scope++
                    else if (isEqual(tokenKeys[i], LEX_OPERATOR)
                        && (isEqual(tokenValues[i], ")")
                            || isEqual(tokenValues[i], "]")))

                        # int_scope = internal scope
                        # someting in () or []                       
                        int_scope--
                    ;

                    # Starting a new line ?
                    if isEqual(tokenKeys[i], LEX_LINE) || (
                        isEqual(tokenKeys[i], LEX_KEYWORD) && (
                            isEqual(tokenValues[i], lexer.keywords[lexer.KEYWORD_CLASS])))
                        column = 0 # Reset columns (a new line starts
                                   # with 0 columns)
                        if (!isEqual(tokenKeys[i], LEX_LINE)
                            || _shouldWriteNewLine(i, tokenKeys, tokenValues))

                            _writeTo(fileOutput, "\n")
                        ;
     
                        if scopeNextAdd && isEqual(tokenKeys[i], LEX_LINE)
                            # Means: the current syntax unit requires a body
                            # => Start a new body (or at least add 1 to the
                            # global scope)
                            scope++
                            scopeNextAdd = false
                        ;                       

                        if ((i + 1) < len(tokenKeys)
                            && ((isEqual(tokenKeys[i + 1], LEX_OPERATOR)
                                && isEqual(tokenValues[i + 1], ";"))
                                    || (isEqual(tokenKeys[i + 1], LEX_KEYWORD)
                                && isEqual(tokenValues[i + 1], "else"))))

                            # Srry, the scope just ended
                            scope--
                        ;

                        if ((i + 1) < len(tokenKeys)
                            && tokenKeys[i + 1] != LEX_LINE)
                            # We should write a bit space in front of this line
                            # (because it's not an empty one)

                            for ii = 0, ii < scope + int_scope, ii++
                                _writeTo(fileOutput, tab)
                                if isEqual(tab, "\t")
                                    column += tab_length
                                else
                                    column += tab.length()
                                ;
                            ;
                        ;

                        if isEqual(tokenKeys[i], LEX_LINE)
                            continue
                        ;
                    ;

                    # Should a space be written to the
                    # current buffer ?
                    # 
                    # Not in multi comments: That's because all comments
                    # following the 1. comment line of the multi comment would
                    # be placed one space to the right (in relation to the first
                    # line)
                    if !inMultiComment && i > 0 && _shouldWriteSpace(
                        tokenKeys[i-1],
                        tokenValues[i-1],
                        tokenKeys[i], tokenValues[i])
                            
                        _writeTo(fileOutput, " ")
                        column += 1
                    ;

                    String startValue = null
                    String endValue = null
                    if tokenKeys[i] == LEX_STRING
                        startValue = "\""
                        endValue = startValue
                    else if tokenKeys[i] == LEX_CHAR
                        startValue = "\'"
                        endValue = startValue
                    else if tokenKeys[i] == LEX_COMMENT
                        tokenValues[i].trim()
                        if !tokenValues[i].startsWith("#")
                            tokenValues[i].insert("# ", 0)
                        ;

                        if inMultiComment || ((i + 1) < len(tokenKeys)
                                && tokenKeys[i + 1] != LEX_LINE)
                            endValue = "\n"
                            for ii = 0, ii < scope + int_scope, ii++
                                endValue += tab
                            ;
                        ;
                    else if tokenKeys[i] == LEX_COMMENT_MULTI
                        tokenValues[i].trim()
                        startValue = "## "
                        endValue = " ##"
                    else if tokenKeys[i] == LEX_COMMENT_MULTI_END
                        tokenValues[i].trim()
                        inMultiComment = false

                        if tokenValues[i].isEmpty()
                            endValue = "##"
                        else
                            endValue = " ##"
                        ;
                    else if tokenKeys[i] == LEX_COMMENT_MULTI_START
                        tokenValues[i].trim()
                        inMultiComment = true
                        startValue = "## "
                        endValue = "\n"
                        for ii = 0, ii < scope + int_scope, ii++
                            endValue += tab
                        ;
                    ;
                    
                    # We might want to start a new line in front of the
                    # current token
                    if int_scope > 0 && column >= startSoftCut && isEqual(tokenKeys[i], LEX_OPERATOR) && (
                        isEqual(tokenValues[i], "||")
                        || isEqual(tokenValues[i], "&&"))
                        
                        column = 0
                        _writeTo(fileOutput, "\n")
                        for ii = 0, ii < scope + int_scope, ii++
                            _writeTo(fileOutput, tab)
                            if isEqual(tab, "\t")
                                column += tab_length
                            else
                                column += tab.length()
                            ;
                        ;
                    ;

                    # We might want to start a new line in front of the
                    # current token
                    if int_scope > 0 && (tokenKeys[i] == LEX_SYMBOL
                        || tokenKeys[i] == LEX_STRING
                        || tokenKeys[i] == LEX_CHAR)
                        
                        lenToken = tokenValues[i].length()
                        if (tokenKeys[i] == LEX_STRING
                            || tokenKeys[i] == LEX_CHAR)

                            lenToken += 2
                        ;

                        if column + lenToken >= startHardCut 
                            column = 0
                            _writeTo(fileOutput, "\n")
                            for ii = 0, ii < scope + int_scope, ii++
                                _writeTo(fileOutput, tab)
                                if isEqual(tab, "\t")
                                    column += tab_length
                                else
                                    column += tab.length()
                                ;
                            ;
                        ;
                    ;

                    if startValue != null
                        _writeTo(fileOutput, startValue)
                        column += startValue.length()
                    ;
    
                    # Write the token's value to the buffer (e.g. file)
                    _writeTo(fileOutput, tokenValues[i])
                    column += tokenValues[i].length()

                    if endValue != null
                        _writeTo(fileOutput, endValue)
                        column += endValue.length()
                    ;

                    # We might want to start a new line
                    # following the current token
                    if int_scope > 0 && column >= startSoftCut && isEqual(tokenKeys[i], LEX_OPERATOR) && (
                        isEqual(tokenValues[i], ","))
                        
                        column = 0
                        _writeTo(fileOutput, "\n")
                        for ii = 0, ii < scope + int_scope, ii++
                            _writeTo(fileOutput, tab)
                            if isEqual(tab, "\t")
                                column += tab_length
                            else
                                column += tab.length()
                            ;
                        ;
                    ;
                ;
            ;

            return true
        ;
    ;
;
